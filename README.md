# NeuroGate ğŸ§ âš¡

A **Distributed, Fault-Tolerant Inference Gateway for LLMs** built with Go, gRPC, Kubernetes, and Terraform.

![Architecture](https://img.shields.io/badge/Architecture-Microservices-blue)
![Go Version](https://img.shields.io/badge/Go-1.22+-00ADD8?logo=go)
![Kubernetes](https://img.shields.io/badge/Kubernetes-Kind-326CE5?logo=kubernetes)
![Terraform](https://img.shields.io/badge/IaC-Terraform-7B42BC?logo=terraform)

## ğŸ¯ Overview

NeuroGate is not a chatbotâ€”it's the **platform that serves the chatbot**. It provides:

- **Load Balancing**: Round-robin distribution across multiple LLM workers
- **Fault Tolerance**: Circuit breaker pattern to handle failing workers gracefully
- **Observability**: Prometheus metrics + Grafana dashboards for tokens/second, latency, etc.
- **Cloud-Native**: Kubernetes deployment with Terraform IaC

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CLIENTS                                  â”‚
â”‚                     curl / SDK / Web Application                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ HTTP (REST)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GATEWAY (Load Balancer)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ API Auth   â”‚  â”‚ Round Robin LB  â”‚  â”‚ Circuit Breaker (3 fails)â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ gRPC
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Worker 1     â”‚  â”‚    Worker 2     â”‚  â”‚    Worker 3     â”‚
â”‚  (gRPC Server)  â”‚  â”‚  (gRPC Server)  â”‚  â”‚  (gRPC Server)  â”‚
â”‚  :50051/:9090   â”‚  â”‚  :50052/:9092   â”‚  â”‚  :50053/:9093   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ HTTP
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Ollama      â”‚
                    â”‚  (LLM Engine)   â”‚
                    â”‚    :11434       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
neurogate/
â”œâ”€â”€ api/proto/              # gRPC Protocol Buffer definitions
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ gateway/            # Load Balancer REST API
â”‚   â””â”€â”€ worker/             # gRPC Worker connecting to Ollama
â”œâ”€â”€ deploy/
â”‚   â”œâ”€â”€ k8s/                # Kubernetes YAML manifests
â”‚   â”œâ”€â”€ terraform/          # Terraform IaC for K8s resources
â”‚   â””â”€â”€ prometheus/         # Prometheus configuration
â”œâ”€â”€ pkg/
â”‚   â”œâ”€â”€ circuitbreaker/     # Circuit Breaker pattern implementation
â”‚   â”œâ”€â”€ health/             # Health checking utilities
â”‚   â”œâ”€â”€ logger/             # Structured logging with slog
â”‚   â”œâ”€â”€ metrics/            # Prometheus instrumentation
â”‚   â””â”€â”€ ollama/             # Ollama API client
â”œâ”€â”€ Dockerfile.gateway      # Multi-stage build for Gateway
â”œâ”€â”€ Dockerfile.worker       # Multi-stage build for Worker
â”œâ”€â”€ docker-compose.yaml     # Local development with Docker
â”œâ”€â”€ Makefile                # Build automation
â””â”€â”€ go.mod                  # Go dependencies
```

## ğŸš€ Quick Start

### Prerequisites

- **Go 1.22+**
- **Docker** and **Docker Compose**
- **Ollama** (running locally with a model like `llama3.2`)
- **Kind** (optional, for Kubernetes)
- **Terraform** (optional, for IaC)

### 1. Start Ollama

```bash
# Install Ollama (if not already)
brew install ollama

# Start Ollama and pull a model
ollama serve &
ollama pull llama3.2
```

### 2. Run Locally (No Docker)

```bash
# Terminal 1: Start a worker
make run-worker

# Terminal 2: Start the gateway
make run-gateway

# Terminal 3: Test it!
make demo
```

### 3. Run with Docker Compose

```bash
# Build and start all services
docker-compose up --build

# Test the gateway
curl -X POST http://localhost:8080/prompt \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer neurogate-secret-key-1" \
  -d '{"query": "Explain quantum computing in simple terms"}'
```

### 4. Deploy to Kubernetes (Kind)

```bash
# Build Docker images
make docker

# Create Kind cluster and deploy
make kind-create
make deploy

# Check status
make status

# Test it
make demo-k8s
```

## ğŸ“¡ API Reference

### POST /prompt

Generate text from the LLM.

**Request:**
```bash
curl -X POST http://localhost:8080/prompt \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer neurogate-secret-key-1" \
  -d '{
    "query": "Why is the sky blue?",
    "model": "llama3.2",
    "max_tokens": 500,
    "temperature": 0.7
  }'
```

**Response:**
```json
{
  "request_id": "req-1704567890123456789",
  "response": "The sky appears blue due to a phenomenon called Rayleigh scattering...",
  "model": "llama3.2",
  "tokens": 156,
  "latency_ms": 2340,
  "worker_id": "worker-0"
}
```

### GET /health

Check gateway health status.

### GET /workers

List all workers and their status including circuit breaker state.

## ğŸ“Š Observability

### Prometheus Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `neurogate_gateway_requests_total` | Counter | Total HTTP requests |
| `neurogate_gateway_request_duration_seconds` | Histogram | Request latency |
| `neurogate_gateway_circuit_breaker_state` | Gauge | CB state per worker |
| `neurogate_worker_inference_duration_seconds` | Histogram | LLM inference time |
| `neurogate_worker_tokens_generated_total` | Counter | Tokens generated |
| `neurogate_worker_tokens_per_second` | Gauge | Current TPS |

### Grafana Dashboards

Access Grafana at `http://localhost:3000` (admin/neurogate) with pre-configured dashboards showing:

- Requests per second
- P95 latency
- Tokens per second
- Circuit breaker states

## ğŸ”§ Configuration

### Environment Variables

**Gateway:**
| Variable | Default | Description |
|----------|---------|-------------|
| `HTTP_PORT` | 8080 | HTTP listen port |
| `METRICS_PORT` | 9091 | Prometheus metrics port |
| `WORKER_ADDRESSES` | localhost:50051 | Comma-separated worker addresses |
| `API_KEYS` | (none) | Comma-separated valid API keys |
| `LOG_LEVEL` | info | Log level (debug, info, warn, error) |

**Worker:**
| Variable | Default | Description |
|----------|---------|-------------|
| `GRPC_PORT` | 50051 | gRPC listen port |
| `METRICS_PORT` | 9090 | Prometheus metrics port |
| `OLLAMA_URL` | http://localhost:11434 | Ollama API URL |
| `LOG_LEVEL` | info | Log level |

## ğŸ›¡ï¸ Fault Tolerance

### Circuit Breaker

The gateway implements a circuit breaker for each worker:

- **Closed** (normal): Requests flow through
- **Open** (tripped): After 3 consecutive failures, traffic stops for 30 seconds
- **Half-Open** (testing): One request allowed through to test recovery

```
   [CLOSED] â”€â”€3 failuresâ”€â”€> [OPEN] â”€â”€30s timeoutâ”€â”€> [HALF-OPEN]
       â–²                                                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€successâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                                                          â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€failureâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Make Commands

```bash
make help           # Show all available commands

# Development
make build          # Build all binaries
make test           # Run tests
make lint           # Run linters
make clean          # Clean build artifacts

# Docker
make docker         # Build all Docker images
make docker-push    # Push images to registry

# Kubernetes
make kind-create    # Create Kind cluster
make deploy         # Deploy to K8s
make undeploy       # Remove from K8s
make status         # Show deployment status

# Terraform
make tf-init        # Initialize Terraform
make tf-apply       # Apply Terraform changes

# Demo
make demo           # Test local gateway
make demo-k8s       # Test Kind gateway
```

## ğŸ† Tech Stack Highlights

| Component | Technology | Enterprise Value |
|-----------|------------|------------------|
| **Language** | Go 1.22+ | Cloud-native standard |
| **Communication** | gRPC + Protobuf | High-performance internal comms |
| **Orchestration** | Kubernetes (Kind) | Industry-standard container orchestration |
| **IaC** | Terraform | Infrastructure as code |
| **AI Engine** | Ollama | Local LLM inference |
| **Observability** | Prometheus + Grafana | Industry-standard monitoring |
| **Patterns** | Circuit Breaker | Resilience engineering |

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

Built with â¤ï¸ for learning distributed systems and cloud-native development.
